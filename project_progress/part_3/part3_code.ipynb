{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "272c526c",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "\n",
    "# **DELIVERY 3**\n",
    "## **Ranking & Filtering**\n",
    "\n",
    "</div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dad6efd",
   "metadata": {},
   "source": [
    "### **Main Code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fbff191a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using enriched dataset: C:\\Users\\Pol\\Documents\\POL\\UNI\\WEB\\irwa-search-engine\\data\\fashion_products_dataset_enriched.json\n",
      "Using boolean index:    C:\\Users\\Pol\\Documents\\POL\\UNI\\WEB\\irwa-search-engine\\data\\index\\boolean_inverted_index.json\n",
      "Loaded 28080 documents\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import math\n",
    "from collections import defaultdict, Counter\n",
    "from pathlib import Path\n",
    "import sys\n",
    "from typing import Dict, List, Any, Iterable, Tuple\n",
    "\n",
    "NOTEBOOK_DIR = Path().resolve()\n",
    "REPO_ROOT = NOTEBOOK_DIR.parents[1] if NOTEBOOK_DIR.name in {\"part_1\", \"part_2\", \"part_3\"} else NOTEBOOK_DIR\n",
    "DATA_DIR = REPO_ROOT / \"data\"\n",
    "INDEX_DIR = DATA_DIR / \"index\"\n",
    "\n",
    "sys.path.append(str(REPO_ROOT / \"project_progress\"))\n",
    "from utils.preprocessing import preprocess_text_field  \n",
    "\n",
    "ENRICHED_PATH = DATA_DIR / \"fashion_products_dataset_enriched.json\"\n",
    "INVERTED_PATH = INDEX_DIR / \"boolean_inverted_index.json\"\n",
    "DOCMAP_PATH = INDEX_DIR / \"docid_pid_map.json\"\n",
    "\n",
    "print(f\"Using enriched dataset: {ENRICHED_PATH}\")\n",
    "print(f\"Using boolean index:    {INVERTED_PATH}\")\n",
    "\n",
    "# Load data\n",
    "if not ENRICHED_PATH.exists():\n",
    "    raise FileNotFoundError(ENRICHED_PATH)\n",
    "if not INVERTED_PATH.exists():\n",
    "    raise FileNotFoundError(INVERTED_PATH)\n",
    "\n",
    "docs: List[Dict[str, Any]] = json.loads(ENRICHED_PATH.read_text(encoding=\"utf-8\"))\n",
    "inverted_index: Dict[str, List[int]] = json.loads(INVERTED_PATH.read_text(encoding=\"utf-8\"))\n",
    "docid_to_pid = json.loads(DOCMAP_PATH.read_text(encoding=\"utf-8\"))[\"docid_to_pid\"]\n",
    "\n",
    "N_DOCS = len(docs)\n",
    "print(f\"Loaded {N_DOCS} documents\")\n",
    "\n",
    "# Text fields used for indexing / ranking (same as Part 2)\n",
    "INDEXED_TEXT_FIELDS = [\"title_clean\", \"description_clean\", \"metadata_clean\"]\n",
    "\n",
    "REQUIRED_OUTPUT_FIELDS = [\n",
    "    \"pid\", \"title\", \"description\", \"brand\", \"category\", \"sub_category\",\n",
    "    \"product_details\", \"seller\", \"out_of_stock\", \"selling_price\", \"discount\",\n",
    "    \"actual_price\", \"average_rating\", \"url\"\n",
    "]\n",
    "\n",
    "\n",
    "def _doc_tokens(record: Dict[str, Any], fields: Iterable[str]) -> List[str]:\n",
    "    toks: List[str] = []\n",
    "    for f in fields:\n",
    "        val = record.get(f)\n",
    "        if not val:\n",
    "            continue\n",
    "        toks.extend(str(val).split())\n",
    "    return toks\n",
    "\n",
    "def _query_tokens(q: str) -> List[str]:\n",
    "    proc = preprocess_text_field(q or \"\")\n",
    "    return proc[\"tokens\"]\n",
    "\n",
    "def _intersect_sorted(a: List[int], b: List[int]) -> List[int]:\n",
    "    i = j = 0\n",
    "    out: List[int] = []\n",
    "    while i < len(a) and j < len(b):\n",
    "        if a[i] == b[j]:\n",
    "            out.append(a[i])\n",
    "            i += 1\n",
    "            j += 1\n",
    "        elif a[i] < b[j]:\n",
    "            i += 1\n",
    "        else:\n",
    "            j += 1\n",
    "    return out\n",
    "\n",
    "def _candidate_docs(q_terms: List[str]) -> List[int]:\n",
    "    \"\"\"\n",
    "    AND semantics over the boolean index:\n",
    "    returns doc_ids that contain ALL query terms.\n",
    "    \"\"\"\n",
    "    if not q_terms:\n",
    "        return []\n",
    "    postings_lists: List[List[int]] = []\n",
    "    for t in set(q_terms):\n",
    "        p = inverted_index.get(t)\n",
    "        if not p:\n",
    "            return []\n",
    "        postings_lists.append(p)\n",
    "    postings_lists.sort(key=len)\n",
    "    result = postings_lists[0]\n",
    "    for pl in postings_lists[1:]:\n",
    "        result = _intersect_sorted(result, pl)\n",
    "        if not result:\n",
    "            break\n",
    "    return result\n",
    "\n",
    "# Pre-compute TF, IDF, norms for TF-IDF and stats for BM25\n",
    "term_df: Dict[str, int] = {t: len(pl) for t, pl in inverted_index.items()}  # df(t)\n",
    "\n",
    "# tf per doc and doc lengths\n",
    "doc_tf: Dict[int, Dict[str, int]] = {}\n",
    "doc_len: Dict[int, int] = {}\n",
    "\n",
    "for doc_id, rec in enumerate(docs):\n",
    "    toks = _doc_tokens(rec, INDEXED_TEXT_FIELDS)\n",
    "    tf = Counter(toks)\n",
    "    doc_tf[doc_id] = dict(tf)\n",
    "    doc_len[doc_id] = sum(tf.values())\n",
    "\n",
    "avg_doc_len = sum(doc_len.values()) / max(N_DOCS, 1)\n",
    "\n",
    "# TF-IDF (log-tf, log2(N/df)) \n",
    "idf_tfidf: Dict[str, float] = {}\n",
    "for t, df in term_df.items():\n",
    "    if df > 0:\n",
    "        idf_tfidf[t] = math.log2(N_DOCS / df)\n",
    "    else:\n",
    "        idf_tfidf[t] = 0.0\n",
    "\n",
    "tfidf_weights: Dict[int, Dict[str, float]] = {}\n",
    "doc_norms: Dict[int, float] = {}\n",
    "\n",
    "for doc_id, tf_map in doc_tf.items():\n",
    "    w_map: Dict[str, float] = {}\n",
    "    sq_sum = 0.0\n",
    "    for t, f in tf_map.items():\n",
    "        if f <= 0:\n",
    "            continue\n",
    "        w = (1.0 + math.log2(f)) * idf_tfidf.get(t, 0.0)\n",
    "        if w != 0.0:\n",
    "            w_map[t] = w\n",
    "            sq_sum += w * w\n",
    "    tfidf_weights[doc_id] = w_map\n",
    "    doc_norms[doc_id] = math.sqrt(sq_sum) if sq_sum > 0 else 0.0\n",
    "\n",
    "# BM25 stats\n",
    "# idf formula: log( (N - df + 0.5) / (df + 0.5) + 1 )\n",
    "idf_bm25: Dict[str, float] = {}\n",
    "for t, df in term_df.items():\n",
    "    num = N_DOCS - df + 0.5\n",
    "    den = df + 0.5\n",
    "    idf_bm25[t] = math.log(num / den + 1.0)\n",
    "\n",
    "k1 = 1.5\n",
    "b = 0.75\n",
    "\n",
    "\n",
    "# Ranking 1: TF-IDF + cosine similarity\n",
    "def _tfidf_cosine_scores(q_terms: List[str], candidate_ids: List[int]) -> Dict[int, float]:\n",
    "    if not candidate_ids:\n",
    "        return {}\n",
    "\n",
    "    # query weights\n",
    "    q_tf = Counter(q_terms)\n",
    "    q_weights: Dict[str, float] = {}\n",
    "    q_sq_sum = 0.0\n",
    "    for t, f in q_tf.items():\n",
    "        if f <= 0:\n",
    "            continue\n",
    "        w = (1.0 + math.log2(f)) * idf_tfidf.get(t, 0.0)\n",
    "        if w != 0.0:\n",
    "            q_weights[t] = w\n",
    "            q_sq_sum += w * w\n",
    "    q_norm = math.sqrt(q_sq_sum) if q_sq_sum > 0 else 0.0\n",
    "    if q_norm == 0.0:\n",
    "        return {}\n",
    "\n",
    "    scores: Dict[int, float] = {}\n",
    "    for did in candidate_ids:\n",
    "        d_weights = tfidf_weights.get(did, {})\n",
    "        denom = doc_norms.get(did, 0.0)\n",
    "        if denom == 0.0:\n",
    "            continue\n",
    "        dot = 0.0\n",
    "        for t, qw in q_weights.items():\n",
    "            dw = d_weights.get(t)\n",
    "            if dw is not None:\n",
    "                dot += qw * dw\n",
    "        if dot > 0.0:\n",
    "            scores[did] = dot / (q_norm * denom)\n",
    "    return scores\n",
    "\n",
    "def search_tfidf_cosine(query: str, k: int = 20) -> List[Dict[str, Any]]:\n",
    "    q_terms = _query_tokens(query)\n",
    "    cand_ids = _candidate_docs(q_terms)\n",
    "    scores = _tfidf_cosine_scores(q_terms, cand_ids)\n",
    "    ranked = sorted(scores.items(), key=lambda x: x[1], reverse=True)[:k]\n",
    "\n",
    "    results: List[Dict[str, Any]] = []\n",
    "    for did, s in ranked:\n",
    "        rec = docs[did]\n",
    "        view = {f: rec.get(f) for f in REQUIRED_OUTPUT_FIELDS if f in rec}\n",
    "        view[\"pid\"] = rec.get(\"pid\") or docid_to_pid.get(str(did))\n",
    "        view[\"score_tfidf\"] = s\n",
    "        results.append(view)\n",
    "    return results\n",
    "\n",
    "\n",
    "# Ranking 2: BM25\n",
    "def _bm25_scores(q_terms: List[str], candidate_ids: List[int]) -> Dict[int, float]:\n",
    "    if not candidate_ids:\n",
    "        return {}\n",
    "    q_unique = list(set(q_terms))  # BM25 usually ignores query term frequency or uses min(1, tf)\n",
    "\n",
    "    scores: Dict[int, float] = {}\n",
    "    for did in candidate_ids:\n",
    "        tf_map = doc_tf.get(did, {})\n",
    "        dl = doc_len.get(did, 0)\n",
    "        if dl == 0:\n",
    "            continue\n",
    "        score = 0.0\n",
    "        for t in q_unique:\n",
    "            f = tf_map.get(t, 0)\n",
    "            if f <= 0:\n",
    "                continue\n",
    "            idf = idf_bm25.get(t, 0.0)\n",
    "            denom = f + k1 * (1.0 - b + b * dl / avg_doc_len)\n",
    "            score += idf * (f * (k1 + 1.0) / denom)\n",
    "        if score != 0.0:\n",
    "            scores[did] = score\n",
    "    return scores\n",
    "\n",
    "def search_bm25(query: str, k: int = 20) -> List[Dict[str, Any]]:\n",
    "    q_terms = _query_tokens(query)\n",
    "    cand_ids = _candidate_docs(q_terms)\n",
    "    scores = _bm25_scores(q_terms, cand_ids)\n",
    "    ranked = sorted(scores.items(), key=lambda x: x[1], reverse=True)[:k]\n",
    "\n",
    "    results: List[Dict[str, Any]] = []\n",
    "    for did, s in ranked:\n",
    "        rec = docs[did]\n",
    "        view = {f: rec.get(f) for f in REQUIRED_OUTPUT_FIELDS if f in rec}\n",
    "        view[\"pid\"] = rec.get(\"pid\") or docid_to_pid.get(str(did))\n",
    "        view[\"score_bm25\"] = s\n",
    "        results.append(view)\n",
    "    return results\n",
    "\n",
    "\n",
    "# Ranking 3: Custom score (TF-IDF + numeric boosts)\n",
    "def _numeric_boost(rec: Dict[str, Any]) -> float:\n",
    "    \"\"\"\n",
    "    Combines rating, discount, price and stock availability into a single multiplier.\n",
    "    Idea:\n",
    "      - Prefer in-stock items\n",
    "      - Higher rating and higher discount -> better\n",
    "      - Slight preference for cheaper items (within a cap)\n",
    "    \"\"\"\n",
    "    rating = rec.get(\"average_rating_num\") or 0.0\n",
    "    discount = rec.get(\"discount_pct\") or 0\n",
    "    price = rec.get(\"selling_price_num\") or rec.get(\"actual_price_num\") or 0.0\n",
    "    out_of_stock = rec.get(\"out_of_stock_bool\")\n",
    "\n",
    "    # Normalize\n",
    "    rating_norm = max(0.0, min(rating / 5.0, 1.0))          # 0â€“1\n",
    "    discount_norm = max(0.0, min(discount / 80.0, 1.0))     # assume 80% is \"very high\"\n",
    "    price_cap = 4000.0\n",
    "    if price <= 0:\n",
    "        price_norm = 0.5\n",
    "    else:\n",
    "        price_norm = 1.0 - min(price, price_cap) / price_cap  # cheaper -> closer to 1\n",
    "\n",
    "    stock_factor = 1.0 if not out_of_stock else 0.2         # strong penalty if out of stock\n",
    "\n",
    "    # Weighted combination -> multiplier around ~[0.5, 2]\n",
    "    boost = 1.0 + 0.5 * rating_norm + 0.4 * discount_norm + 0.3 * price_norm\n",
    "    return boost * stock_factor\n",
    "\n",
    "def search_custom_score(query: str, k: int = 20) -> List[Dict[str, Any]]:\n",
    "    q_terms = _query_tokens(query)\n",
    "    cand_ids = _candidate_docs(q_terms)\n",
    "\n",
    "    # base relevance: TF-IDF cosine\n",
    "    base_scores = _tfidf_cosine_scores(q_terms, cand_ids)\n",
    "    if not base_scores:\n",
    "        return []\n",
    "\n",
    "    final_scores: Dict[int, float] = {}\n",
    "    for did, base in base_scores.items():\n",
    "        rec = docs[did]\n",
    "        boost = _numeric_boost(rec)\n",
    "        final_scores[did] = base * boost\n",
    "\n",
    "    ranked = sorted(final_scores.items(), key=lambda x: x[1], reverse=True)[:k]\n",
    "\n",
    "    results: List[Dict[str, Any]] = []\n",
    "    for did, s in ranked:\n",
    "        rec = docs[did]\n",
    "        view = {f: rec.get(f) for f in REQUIRED_OUTPUT_FIELDS if f in rec}\n",
    "        view[\"pid\"] = rec.get(\"pid\") or docid_to_pid.get(str(did))\n",
    "        view[\"score_custom\"] = s\n",
    "        results.append(view)\n",
    "    return results\n",
    "\n",
    "# Small helper to try all three methods with the same query\n",
    "def compare_rankers(query: str, k: int = 5):\n",
    "    print(f\"\\n=== Query: {query!r} ===\")\n",
    "\n",
    "    tfidf_res = search_tfidf_cosine(query, k=k)\n",
    "    bm25_res = search_bm25(query, k=k)\n",
    "    custom_res = search_custom_score(query, k=k)\n",
    "\n",
    "    def _show(label: str, res: List[Dict[str, Any]], score_key: str):\n",
    "        print(f\"\\n-- {label} --\")\n",
    "        for r in res:\n",
    "            title = (r.get(\"title\") or \"\")[:60]\n",
    "            pid = r.get(\"pid\")\n",
    "            s = r.get(score_key)\n",
    "            print(f\"{pid} | {s:.4f} | {title}\")\n",
    "\n",
    "    _show(\"TF-IDF + cosine\", tfidf_res, \"score_tfidf\")\n",
    "    _show(\"BM25\", bm25_res, \"score_bm25\")\n",
    "    _show(\"Custom score\", custom_res, \"score_custom\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8356618d",
   "metadata": {},
   "source": [
    "### **Testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c5fd04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Query: 'women full sleeve sweatshirt cotton' ===\n",
      "\n",
      "-- TF-IDF + cosine --\n",
      "SWSFZVTTQCB4SJ7F | 0.7305 | Full Sleeve Solid Women Sweatshirt\n",
      "SWSFQGS456JAZCQB | 0.6561 | Full Sleeve Printed Women Sweatshirt\n",
      "SWSFZVTNGM4HG8BC | 0.6339 | Full Sleeve Printed Women Sweatshirt\n",
      "SWSFYTYMNTBNARUN | 0.6237 | Full Sleeve Solid Women Sweatshirt\n",
      "SWSFYRKYAHH4HHSM | 0.6070 | Full Sleeve Printed Women Sweatshirt\n",
      "\n",
      "-- BM25 --\n",
      "SWSFVZRFS7GHGKSF | 10.2591 | Full Sleeve Solid Women Sweatshirt\n",
      "SWSFYFFFFYZ896TJ | 9.9860 | Full Sleeve Printed Women Sweatshirt\n",
      "SWSFXMFPDVRHYYPH | 9.9796 | Full Sleeve Striped Women Sweatshirt\n",
      "SWSFXMFPPZGDQGMW | 9.9796 | Full Sleeve Striped Women Sweatshirt\n",
      "SWSFYFFYQ7Z3ZKN6 | 9.9541 | Full Sleeve Printed Women Sweatshirt\n",
      "\n",
      "-- Custom score --\n",
      "SWSFZVTNGM4HG8BC | 1.2278 | Full Sleeve Printed Women Sweatshirt\n",
      "SWSFYTYMNTBNARUN | 1.2057 | Full Sleeve Solid Women Sweatshirt\n",
      "SWSFY38ADYPVZHYZ | 1.1757 | Full Sleeve Printed Women Sweatshirt\n",
      "SWSFY382UZHFBCNB | 1.1277 | Full Sleeve Printed Women Sweatshirt\n",
      "SWSFZ2H4KMYXZXX7 | 1.1058 | Full Sleeve Solid Women Sweatshirt\n",
      "\n",
      "=== Query: 'men slim jeans blue' ===\n",
      "\n",
      "-- TF-IDF + cosine --\n",
      "JEAFRAQXEKGUPNUN | 0.4843 | Slim Men Blue Jeans\n",
      "JEAFSKYHZHSZZC9S | 0.4559 | Slim Men Blue Jeans\n",
      "JEAFQF6JBUSEXHVF | 0.4447 | Slim Men Blue Jeans\n",
      "JEAFSKYHRVZSABPR | 0.4423 | Slim Men Blue Jeans\n",
      "JEAFSKYHTE76YWH7 | 0.4423 | Slim Men Blue Jeans\n",
      "\n",
      "-- BM25 --\n",
      "JEAEVJGUSXRNSHRY | 10.2389 | Slim Men Dark Blue Jeans\n",
      "JEAFSKYHRVZSABPR | 10.1051 | Slim Men Blue Jeans\n",
      "JEAFSKYHTE76YWH7 | 10.1051 | Slim Men Blue Jeans\n",
      "JEAEHGRJSGGYEYYX | 10.0824 | Slim Men Light Blue Jeans\n",
      "JEAFWZXTFGMP9GCN | 9.9718 | Slim Men Blue Jeans\n",
      "\n",
      "-- Custom score --\n",
      "JEAFQF6JBUSEXHVF | 0.7882 | Slim Men Blue Jeans\n",
      "JEAFSKYHZHSZZC9S | 0.7670 | Slim Men Blue Jeans\n",
      "JEAFSKYHRVZSABPR | 0.7660 | Slim Men Blue Jeans\n",
      "JEAFESND4QWQUBZD | 0.7660 | Slim Men Blue Jeans\n",
      "JEAFEKQZ4C2Z6GCX | 0.7643 | Slim Men Blue Jeans\n"
     ]
    }
   ],
   "source": [
    "compare_rankers(\"women full sleeve sweatshirt cotton\", k=5)\n",
    "compare_rankers(\"men slim jeans blue\", k=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "irwa_venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
